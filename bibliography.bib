% This sample bib file is taken from the "Dissertation-Template-KIT", licensed under MIT license, (c) 2019 Grinberg, Michael
%
% Source:
% https://gitlab-ext.iosb.fraunhofer.de/grinbe/Dissertation-Template-KIT/raw/5257bda3baf14443b4977ab674f9b4c3296407e2/bib/example.bib
%
% Permission is hereby granted, free of charge, to any person obtaining a copy
of this template and associated documentation files (the "Template"), to deal
in the Template without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Template, and to permit persons to whom the Template is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Template.

THE TEMPLATE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE TEMPLATE OR THE USE OR OTHER DEALINGS IN THE
TEMPLATE.
%
%
%

% This file was created with JabRef 2.10.
% Encoding: UTF8
@inproceedings{zoph2020learning,
  title={Learning data augmentation strategies for object detection},
  author={Zoph, Barret and Cubuk, Ekin D and Ghiasi, Golnaz and Lin, Tsung-Yi and Shlens, Jonathon and Le, Quoc V},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXVII 16},
  pages={566--583},
  year={2020},
  organization={Springer}
}
@article{nesteruk2024image,
  title={Image Dataset Augmentation},
  author={Nesteruk, Sergey and Illarionova, Svetlana and Somov, Andrey},
  journal={Measurements and Instrumentation for Machine Vision},
  pages={110},
  year={2024},
  publisher={CRC Press}
}
@article{SONG2022106706,
title = {CT2US: Cross-modal transfer learning for kidney segmentation in ultrasound images with synthesized data},
journal = {Ultrasonics},
volume = {122},
pages = {106706},
year = {2022},
issn = {0041-624X},
doi = {https://doi.org/10.1016/j.ultras.2022.106706},
url = {https://www.sciencedirect.com/science/article/pii/S0041624X22000191},
author = {Yuxin Song and Jing Zheng and Long Lei and Zhipeng Ni and Baoliang Zhao and Ying Hu},
keywords = {Cross modality, Kidney segmentation, Transfer learning, Ultrasound imaging}
}
@ARTICLE{8972568,
  author={Yan, Mengyuan and Zhu, Yilin and Jin, Ning and Bohg, Jeannette},
  journal={IEEE Robotics and Automation Letters}, 
  title={Self-Supervised Learning of State Estimation for Manipulating Deformable Linear Objects}, 
  year={2020},
  volume={5},
  number={2},
  pages={2372-2379},
  keywords={State estimation;Predictive models;Image segmentation;Robots;Physics;Deformable models;Aerospace electronics;Visual learning;deep learning in robotics and automation;perception for grasping and manipulation},
  doi={10.1109/LRA.2020.2969931}}
@incollection{LeCun1995-LECCNF,
	author = {Yann LeCun and Yoshua Bengio},
	booktitle = {Handbook of Brain Theory and Neural Networks},
	editor = {Michael A. Arbib},
	pages = {3361},
	publisher = {MIT Press},
	title = {Convolutional Networks for Images, Speech, and Time Series},
	year = {1995}
}

@inproceedings{inproceedings,
author = {Nazari, Farnaz and Yan, Wei},
year = {2021},
month = {09},
pages = {},
title = {CNN vs. DNN: comparing the two neural networks performance in predicting building operational energy with respect to the building shape},
doi = {10.26868/25222708.2021.30735}
}
@article{4e568dfccc734aa6a8184f781bac6353,
title = "Taming Hyper-Parameters in Deep Learning Systems",
author = "Luo Mai and Alexandros Koliousis and Guo Li and Andrei-Octavian Brabete and Peter Pietzuch",
year = "2019",
month = jul,
day = "25",
doi = "10.1145/3352020.3352029",
language = "English",
volume = "53",
pages = "52–58",
journal = "Operating Systems Review",
issn = "0163-5980",
publisher = "Association for Computing Machinery (ACM)",
number = "1",
}
@book{russel2010,
  added-at = {2020-02-01T18:23:11.000+0100},
  author = {Russell, Stuart and Norvig, Peter},
  biburl = {https://www.bibsonomy.org/bibtex/20533b732950d1c5ab4ac12d4f32fe637/mialhoma},
  edition = 3,
  interhash = {53908a52dd4c6c8e39f93f4ffc8341be},
  intrahash = {0533b732950d1c5ab4ac12d4f32fe637},
  keywords = {ties4530},
  publisher = {Prentice Hall},
  timestamp = {2020-02-01T18:23:11.000+0100},
  title = {Artificial Intelligence: A Modern Approach},
  year = 2010
}
@conference{0706bf17a845490688ef4d7d19df65ba,
title = "Activation functions: comparison of trends in practice and research for deep learning",
author = "Nwankpa, {Chigozie Enyinna} and Winifred Ijomah and Anthony Gachagan and Stephen Marshall",
year = "2021",
month = jan,
day = "11",
language = "English",
pages = "124 -- 133",
note = "2nd International Conference on Computational Sciences and Technology, (INCCST) ; Conference date: 17-12-2020 Through 19-12-2020",
url = "https://inccst.muet.edu.pk/pdf/23.%20Activation%20Functions%20Comparison%20of%20Trends%20in%20Practice%20and%20Research%20for%20Deep%20Learning.pdf",
}
@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@article{tammina2019transfer,
  title={Transfer learning using vgg-16 with deep convolutional neural network for classifying images},
  author={Tammina, Srikanth},
  journal={International Journal of Scientific and Research Publications (IJSRP)},
  volume={9},
  number={10},
  pages={143--150},
  year={2019}
}
@article{guan2019deep,
  title={Deep convolutional neural network VGG-16 model for differential diagnosing of papillary thyroid carcinomas in cytological images: a pilot study},
  author={Guan, Qing and Wang, Yunjun and Ping, Bo and Li, Duanshu and Du, Jiajun and Qin, Yu and Lu, Hongtao and Wan, Xiaochun and Xiang, Jun},
  journal={Journal of Cancer},
  volume={10},
  number={20},
  pages={4876},
  year={2019},
  publisher={Ivyspring International Publisher}
}
@inproceedings{simonyan2015a,
  edition = {},
  number = {},
  journal = {3rd International Conference on Learning Representations (ICLR 2015)},
  pages = {1-14},
  publisher = {Computational and Biological Learning Society},
  school = {},
  title = {Very deep convolutional networks for large-scale image recognition},
  volume = {},
  author = {Simonyan, K and Zisserman, A},
  editor = {},
  year = {2015},
  organizer = {},
  series = {}
}
@article{Bouraya2021,
title = {Deep Learning based Neck Models for Object Detection: A Review and a Benchmarking Study},
journal = {International Journal of Advanced Computer Science and Applications},
doi = {10.14569/IJACSA.2021.0121119},
url = {http://dx.doi.org/10.14569/IJACSA.2021.0121119},
year = {2021},
publisher = {The Science and Information Organization},
volume = {12},
number = {11},
author = {Sara Bouraya and Abdessamad Belangour}
}
@INPROCEEDINGS {9710108,
author = {J. Li and S. Bian and A. Zeng and C. Wang and B. Pang and W. Liu and C. Lu},
booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {Human Pose Regression with Residual Log-likelihood Estimation},
year = {2021},
volume = {},
issn = {},
pages = {11005-11014},
doi = {10.1109/ICCV48922.2021.01084},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.01084},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@InProceedings{Sun_2018_ECCV,
author = {Sun, Xiao and Xiao, Bin and Wei, Fangyin and Liang, Shuang and Wei, Yichen},
title = {Integral Human Pose Regression},
booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
}
@InProceedings{10.1007/978-3-319-46484-8_29,
author="Newell, Alejandro
and Yang, Kaiyu
and Deng, Jia",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Stacked Hourglass Networks for Human Pose Estimation",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="483--499",
isbn="978-3-319-46484-8"
}

@InProceedings{Toshev_2014_CVPR,
author = {Toshev, Alexander and Szegedy, Christian},
title = {DeepPose: Human Pose Estimation via Deep Neural Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2014}
}
@InProceedings{Liu_2018_CVPR,
author = {Liu, Shu and Qi, Lu and Qin, Haifang and Shi, Jianping and Jia, Jiaya},
title = {Path Aggregation Network for Instance Segmentation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}
@article{Wang2019CSPNetAN,
  title={CSPNet: A New Backbone that can Enhance Learning Capability of CNN},
  author={Chien-Yao Wang and Hong-Yuan Mark Liao and I-Hau Yeh and Yueh-Hua Wu and Ping-Yang Chen and Jun-Wei Hsieh},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2019},
  pages={1571-1580},
  url={https://api.semanticscholar.org/CorpusID:208310312}
}
@article{wang2024yolov10,
  title={YOLOv10: Real-Time End-to-End Object Detection},
  author={Wang, Ao and Chen, Hui and Liu, Lihao and Chen, Kai and Lin, Zijia and Han, Jungong and Ding, Guiguang},
  journal={arXiv preprint arXiv:2405.14458},
  year={2024}
}
@InProceedings{Redmon_2016_CVPR,
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
title = {You Only Look Once: Unified, Real-Time Object Detection},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}
@inproceedings{NIPS2015_14bfa6bb,
 author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
 volume = {28},
 year = {2015}
}

@InProceedings{Girshick_2015_ICCV,
author = {Girshick, Ross},
title = {Fast R-CNN},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {December},
year = {2015}
}
@inproceedings{NIPS2012_c399862d,
 author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {ImageNet Classification with Deep Convolutional Neural Networks},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf},
 volume = {25},
 year = {2012}
}

@InProceedings{Girshick_2014_CVPR,
author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
title = {Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2014}
}
@ARTICLE{10028728,
  author={Zou, Zhengxia and Chen, Keyan and Shi, Zhenwei and Guo, Yuhong and Ye, Jieping},
  journal={Proceedings of the IEEE}, 
  title={Object Detection in 20 Years: A Survey}, 
  year={2023},
  volume={111},
  number={3},
  pages={257-276},
  keywords={Object detection;Detectors;Computer vision;Feature extraction;Deep learning;Convolutional neural networks;Computer vision;convolutional neural networks (CNNs);deep learning;object detection;technical evolution},
  doi={10.1109/JPROC.2023.3238524}}
@InProceedings{Sun_2019_CVPR,
author = {Sun, Ke and Xiao, Bin and Liu, Dong and Wang, Jingdong},
title = {Deep High-Resolution Representation Learning for Human Pose Estimation},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2019}
}
@article{voulodimos2018deep,
  title={Deep learning for computer vision: A brief review},
  author={Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
  journal={Computational intelligence and neuroscience},
  volume={2018},
  year={2018},
  publisher={Hindawi Limited}
}
@article{HAO2020302,
title = {A Brief Survey on Semantic Segmentation with Deep Learning},
journal = {Neurocomputing},
volume = {406},
pages = {302-321},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.11.118},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220305476},
author = {Shijie Hao and Yuan Zhou and Yanrong Guo},
keywords = {Semantic segmentation, Deep learning}
}
@InProceedings{10.1007/978-3-319-46466-4_15,
author="Gordo, Albert
and Almaz{\'a}n, Jon
and Revaud, Jerome
and Larlus, Diane",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Deep Image Retrieval: Learning Global Representations for Image Search",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="241--257",
isbn="978-3-319-46466-4"
}
@Article{fire4040075,
AUTHOR = {Guede-Fernández, Federico and Martins, Leonardo and de Almeida, Rui Valente and Gamboa, Hugo and Vieira, Pedro},
TITLE = {A Deep Learning Based Object Identification System for Forest Fire Detection},
JOURNAL = {Fire},
VOLUME = {4},
YEAR = {2021},
NUMBER = {4},
ARTICLE-NUMBER = {75},
URL = {https://www.mdpi.com/2571-6255/4/4/75},
ISSN = {2571-6255},
DOI = {10.3390/fire4040075}
}
@ARTICLE{8016501,
  author={Rawat, Waseem and Wang, Zenghui},
  journal={Neural Computation}, 
  title={Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review}, 
  year={2017},
  volume={29},
  number={9},
  pages={2352-2449},
  keywords={},
  doi={10.1162/neco_a_00990}}
@INPROCEEDINGS{8892980,
  author={Tensmeyer, Christopher and Martinez, Tony},
  booktitle={2019 International Conference on Document Analysis and Recognition Workshops (ICDARW)}, 
  title={Robust Keypoint Detection}, 
  year={2019},
  volume={5},
  number={},
  pages={1-7},
  keywords={Heating systems;Method of moments;Training;Predictive models;Task analysis;Linear regression;Deep Learning;Convolutional Neural Network;Keypoint Detection},
  doi={10.1109/ICDARW.2019.40072}}
@article{HEISLER2021260,
title = {Optimization of wire harness assembly using human–robot-collaboration},
journal = {Procedia CIRP},
volume = {97},
pages = {260-265},
year = {2021},
note = {8th CIRP Conference of Assembly Technology and Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.05.235},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120314566},
author = {Paul Heisler and Daniel Utsch and Marlene Kuhn and Jörg Franke},
}
@article{NGUYEN2021379,
title = {Manufacturing automation for automotive wiring harnesses},
journal = {Procedia CIRP},
volume = {97},
pages = {379-384},
year = {2021},
note = {8th CIRP Conference of Assembly Technology and Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.05.254},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120314761},
author = {Huong Giang Nguyen and Marlene Kuhn and Jörg Franke}
}
@article{sharma2020study,
  title={Study of supervised learning and unsupervised learning},
  author={Sharma, Ritu and Sharma, Kavya and Khanna, Apurva},
  journal={International Journal for Research in Applied Science and Engineering Technology},
  volume={8},
  number={6},
  pages={588--593},
  year={2020}
}
@INPROCEEDINGS{10284109,
  author={Govoni, Andrea and Laudante, Gianluca and Mirto, Michele and Natale, Ciro and Pirozzi, Salvatore},
  booktitle={2023 9th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Towards the Automation of Wire Harness Manufacturing: A Robotic Manipulator with Sensorized Fingers}, 
  year={2023},
  volume={},
  number={},
  pages={974-979},
  keywords={Automation;Manufacturing processes;Wires;Production;Manuals;Robot sensing systems;Manipulators},
  doi={10.1109/CoDIT58514.2023.10284109}}
@inproceedings{van2012automatic,
  title={Automatic flattening of three-dimensional wiring harnesses for manufacturing},
  author={Van Den Berg, T and La Rocca, G and van Tooren, MJL},
  booktitle={Proceedings of the 28th Congress of the International Council of the Aeronautical Sciences},
  year={2012}
}
@INPROCEEDINGS{9952859,
  author={Lee, Ji Sung and Kim, Donghyung and Roh, Myoungchan and Kim, Joong Bae},
  booktitle={2022 13th International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={Vision Based Deformable Wires Recognition using Point Cloud in Wire Harness Supply}, 
  year={2022},
  volume={},
  number={},
  pages={208-213},
  keywords={Point cloud compression;Industries;Employee welfare;Connectors;Wires;Robot sensing systems;Sensors;wire harness assembly;wire harness supply deformable wires;vision;recognition;point cloud},
  doi={10.1109/ICTC55196.2022.9952859}}
@INPROCEEDINGS{9195380,
  author={Zhou, Hang and Li, Shunchong and Lu, Qi and Qian, Jinwu},
  booktitle={2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM)}, 
  title={A Practical Solution to Deformable Linear Object Manipulation: A Case Study on Cable Harness Connection}, 
  year={2020},
  volume={},
  number={},
  pages={329-333},
  keywords={Connectors;Service robots;Grippers;Cameras;Automation;Three-dimensional displays},
  doi={10.1109/ICARM49381.2020.9195380}}
@article{JIANG201552,
title = {Robotized recognition of a wire harness utilizing tracing operation},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {34},
pages = {52-61},
year = {2015},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2014.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0736584514001069},
author = {Xin Jiang and Yuki Nagaoka and Kazushi Ishii and Satoko Abiko and Teppei Tsujita and Masaru Uchiyama},
keywords = {Flexible object handling, Wire harness mating, Wire tracing},
abstract = {In assembly lines, deformation of the objects makes many efforts on automating the corresponding processes difficult. Mating of a wire harness onto a car body is among the representative tasks. Academically, this kind of problems are known as automatic manipulation of deformable linear objects. Previous technical approaches for solving the problem is characterized by employment of multiple contactless sensors and complex sensor based algorithms. These attempts are verified to be feasible only for simplified environments. The dependence of the approaches on real-time measurement to the state of the deformable targets limits their application in practical factory environment. In this paper, it is proposed to utilize wire tracing operation in recognizing the wire harness for the purpose of automatic mating. This method is inspired from the behaviors of humans demonstrated when they deal with similar problems. The proposed method is implemented and verified in a robot system. The feasibility and effectiveness demonstrated in the preliminary experiments show the potential of the proposed method for substantially simplifying the wire recognition problems which is thought to be crucial for practices in factory environments.}
}

@article{TROMMNAU2019387,
title = {Overview of the State of the Art in the Production Process of Automotive Wire Harnesses, Current Research and Future Trends},
journal = {Procedia CIRP},
volume = {81},
pages = {387-392},
year = {2019},
note = {52nd CIRP Conference on Manufacturing Systems (CMS), Ljubljana, Slovenia, June 12-14, 2019},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2019.03.067},
url = {https://www.sciencedirect.com/science/article/pii/S2212827119303725},
author = {Jerome Trommnau and Jens Kühnle and Jörg Siegert and Robert Inderka and Thomas Bauernhansl},
keywords = {automotive engineering, vehicle electrical system, assembly systems, manufacturing automation, design for manufacture},
abstract = {Today’s automotive wire harness manufacturing process involves a high volume of manual work. However, current and future application requirements like miniaturization of electronic components, monitoring of process parameters, increasing demand of process documentation and rising wages call for a higher degree of automation. This paper presents the state of the art in wire harness assembly, reviews currently available special purpose machinery and equipment as well as their limitations and highlights the challenges of automation. It discusses potentials for automation, current innovations and research and concludes with an overview of current trends in the automotive industry.}
}
@INPROCEEDINGS{10160437,
  author={Kicki, Piotr and Szymko, Amadeusz and Walas, Krzysztof},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={DLOFTBs – Fast Tracking of Deformable Linear Objects with B-splines}, 
  year={2023},
  volume={},
  number={},
  pages={7104-7110},
  keywords={Training;Image segmentation;Three-dimensional displays;Shape;Power cables;Training data;Skeleton},
  doi={10.1109/ICRA48891.2023.10160437}}
@article{doi:10.1177/0278364919841431,
author = {Te Tang and Masayoshi Tomizuka},
title ={Track deformable objects from point clouds with structure preserved registration},
journal = {The International Journal of Robotics Research},
volume = {41},
number = {6},
pages = {599-614},
year = {2022},
doi = {10.1177/0278364919841431},

URL = { 
        https://doi.org/10.1177/0278364919841431
},
eprint = { 
        https://doi.org/10.1177/0278364919841431 
}
,
abstract = { Manipulating deformable objects is a challenging task for robots. The major difficulty 
lies in how to track these objects accurately, robustly, and efficiently, considering they have infinite-dimensional configuration space. 
To deal with these problems, this paper proposes a novel state estimator to track deformable objects from point clouds. A non-rigid registration method, 
named structure preserved registration (SPR), is developed to update the estimation by registering the object model towards the current point cloud measurement.
Both the local structure and the global topology of the deformable object are considered during registration, which improves the estimation robustness under noise,
outliers, and occlusions. The tracking result is further refined by running a dynamic simulation in parallel, which enforces the estimates to satisfy the physical 
constraints of the object. A series of real-time tracking experiments on 1D objects (ropes) and 2D objects (clothes) are performed to evaluate the proposed state estimator.
A wire harness manipulation platform is also introduced where robots can manipulate soft wires to desired shapes and autonomously evaluate the manipulation quality through visual feedback. }
}

@InProceedings{10.1007/978-3-030-01231-1_33,
author="Sun, Xiao
and Xiao, Bin
and Wei, Fangyin
and Liang, Shuang
and Wei, Yichen",
editor="Ferrari, Vittorio
and Hebert, Martial
and Sminchisescu, Cristian
and Weiss, Yair",
title="Integral Human Pose Regression",
booktitle="Computer Vision -- ECCV 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="536--553",
abstract="State-of-the-art human pose estimation methods are based on heat map representation. In spite of the good performance, the representation has a few issues in nature, such as non-differentiable post-processing and quantization error. This work shows that a simple integral operation relates and unifies the heat map representation and joint regression, thus avoiding the above issues. It is differentiable, efficient, and compatible with any heat map based methods. Its effectiveness is convincingly validated via comprehensive ablation experiments under various settings, specifically on 3D pose estimation, for the first time.",
isbn="978-3-030-01231-1"
}
@InProceedings{Tremblay_2018_CVPR_Workshops,
author = {Tremblay, Jonathan and To, Thang and Birchfield, Stan},
title = {Falling Things: A Synthetic Dataset for 3D Object Detection and Pose Estimation},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
month = {June},
year = {2018}
}
@InProceedings{10.1007/978-3-319-24574-4_28,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}
@INPROCEEDINGS {8099589,
author = {T. Lin and P. Dollar and R. Girshick and K. He and B. Hariharan and S. Belongie},
booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Feature Pyramid Networks for Object Detection},
year = {2017},
volume = {},
issn = {1063-6919},
pages = {936-944},
abstract = {Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided in recent object detectors that are based on deep convolutional networks, partially because they are slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available.},
keywords = {feature extraction;detectors;semantics;computer architecture;proposals;object detection;robustness},
doi = {10.1109/CVPR.2017.106},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR.2017.106},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}

@InProceedings{10.1007/978-3-030-01234-2_49,
author="Chen, Liang-Chieh
and Zhu, Yukun
and Papandreou, George
and Schroff, Florian
and Adam, Hartwig",
editor="Ferrari, Vittorio
and Hebert, Martial
and Sminchisescu, Cristian
and Weiss, Yair",
title="Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation",
booktitle="Computer Vision -- ECCV 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="833--851",
abstract="Spatial pyramid pooling module or encode-decoder structure are used in deep neural networks for semantic segmentation task. The former networks are able to encode multi-scale contextual information by probing the incoming features with filters or pooling operations at multiple rates and multiple effective fields-of-view, while the latter networks can capture sharper object boundaries by gradually recovering the spatial information. In this work, we propose to combine the advantages from both methods. Specifically, our proposed model, DeepLabv3+, extends DeepLabv3 by adding a simple yet effective decoder module to refine the segmentation results especially along object boundaries. We further explore the Xception model and apply the depthwise separable convolution to both Atrous Spatial Pyramid Pooling and decoder modules, resulting in a faster and stronger encoder-decoder network. We demonstrate the effectiveness of the proposed model on PASCAL VOC 2012 and Cityscapes datasets, achieving the test set performance of 89{\%} and 82.1{\%} without any post-processing. Our paper is accompanied with a publicly available reference implementation of the proposed models in Tensorflow at https://github.com/tensorflow/models/tree/master/research/deeplab.",
isbn="978-3-030-01234-2"
}

@inproceedings{
dosovitskiy2021an,
title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=YicbFdNTTy}
}
@INPROCEEDINGS {9710580,
author = {Z. Liu and Y. Lin and Y. Cao and H. Hu and Y. Wei and Z. Zhang and S. Lin and B. Guo},
booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
year = {2021},
volume = {},
issn = {},
pages = {9992-10002},
abstract = {This paper presents a new vision Transformer, called Swin Transformer, that capably serves as a general-purpose backbone for computer vision. Challenges in adapting Transformer from language to vision arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text. To address these differences, we propose a hierarchical Transformer whose representation is computed with Shifted windows. The shifted windowing scheme brings greater efficiency by limiting self-attention computation to non-overlapping local windows while also allowing for cross-window connection. This hierarchical architecture has the flexibility to model at various scales and has linear computational complexity with respect to image size. These qualities of Swin Transformer make it compatible with a broad range of vision tasks, including image classification (87.3 top-1 accuracy on ImageNet-1K) and dense prediction tasks such as object detection (58.7 box AP and 51.1 mask AP on COCO test-dev) and semantic segmentation (53.5 mIoU on ADE20K val). Its performance surpasses the previous state-of-the-art by a large margin of +2.7 box AP and +2.6 mask AP on COCO, and +3.2 mIoU on ADE20K, demonstrating the potential of Transformer-based models as vision backbones. The hierarchical design and the shifted window approach also prove beneficial for all-MLP architectures. The code and models are publicly available at https://github.com/microsoft/Swin-Transformer.},
keywords = {image segmentation;computer vision;visualization;computational modeling;semantics;object detection;computer architecture},
doi = {10.1109/ICCV48922.2021.00986},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00986},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@inproceedings{NIPS2017_3f5ee243,
 author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, \L ukasz and Polosukhin, Illia},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. Von Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Attention is All you Need},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
 volume = {30},
 year = {2017}
}
@ARTICLE{7485869,
  author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks}, 
  year={2017},
  volume={39},
  number={6},
  pages={1137-1149},
  keywords={Proposals;Object detection;Convolutional codes;Feature extraction;Search problems;Detectors;Training;Object detection;region proposal;convolutional neural network},
  doi={10.1109/TPAMI.2016.2577031}}
@InProceedings{He_2017_ICCV,
author = {He, Kaiming and Gkioxari, Georgia and Dollar, Piotr and Girshick, Ross},
title = {Mask R-CNN},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
month = {Oct},
year = {2017}
}
@InProceedings{10.1007/978-3-030-20890-5_42,
author="De Gregorio, Daniele
and Palli, Gianluca
and Di Stefano, Luigi",
editor="Jawahar, C. V.
and Li, Hongdong
and Mori, Greg
and Schindler, Konrad",
title="Let's Take a Walk on Superpixels Graphs: Deformable Linear Objects Segmentation and Model Estimation",
booktitle="Computer Vision -- ACCV 2018",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="662--677",
abstract="While robotic manipulation of rigid objects is quite straightforward, coping with deformable objects is an open issue. More specifically, tasks like tying a knot, wiring a connector or even surgical suturing deal with the domain of Deformable Linear Objects (DLOs). In particular the detection of a DLO is a non-trivial problem especially under clutter and occlusions (as well as self-occlusions). The pose estimation of a DLO results into the identification of its parameters related to a designed model, e.g. a basis spline. It follows that the stand-alone segmentation of a DLO might not be sufficient to conduct a full manipulation task. This is why we propose a novel framework able to perform both a semantic segmentation and b-spline modeling of multiple deformable linear objects simultaneously without strict requirements about environment (i.e. the background). The core algorithm is based on biased random walks over the Region Adiacency Graph built on a superpixel oversegmentation of the source image. The algorithm is initialized by a Convolutional Neural Networks that detects the DLO's endcaps. An open source implementation of the proposed approach is also provided to easy the reproduction of the whole detection pipeline along with a novel cables dataset in order to encourage further experiments.",
isbn="978-3-030-20890-5"
}

@article{DBLP:journals/corr/VaswaniSPUJGKP17,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.03762},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@ARTICLE{7803544,
  author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation}, 
  year={2017},
  volume={39},
  number={12},
  pages={2481-2495},
  keywords={Decoding;Neural networks;Training;Computer architecture;Image segmentation;Semantics;Convolutional codes;Deep convolutional neural networks;semantic pixel-wise segmentation;indoor scenes;road scenes;encoder;decoder;pooling;upsampling},
  doi={10.1109/TPAMI.2016.2644615}}
@article{DBLP:journals/corr/abs-1804-06534,
  author       = {Jonathan Tremblay and
                  Thang To and
                  Stan Birchfield},
  title        = {Falling Things: {A} Synthetic Dataset for 3D Object Detection and
                  Pose Estimation},
  journal      = {CoRR},
  volume       = {abs/1804.06534},
  year         = {2018},
  url          = {http://arxiv.org/abs/1804.06534},
  eprinttype    = {arXiv},
  eprint       = {1804.06534},
  timestamp    = {Mon, 13 Aug 2018 16:48:39 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1804-06534.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/abs-1711-08229,
  author       = {Xiao Sun and
                  Bin Xiao and
                  Shuang Liang and
                  Yichen Wei},
  title        = {Integral Human Pose Regression},
  journal      = {CoRR},
  volume       = {abs/1711.08229},
  year         = {2017},
  url          = {http://arxiv.org/abs/1711.08229},
  eprinttype    = {arXiv},
  eprint       = {1711.08229},
  timestamp    = {Thu, 15 Feb 2024 19:05:33 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1711-08229.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@misc{azad2023loss,
      title={Loss Functions in the Era of Semantic Segmentation: A Survey and Outlook}, 
      author={Reza Azad and Moein Heidary and Kadir Yilmaz and Michael Hüttemann and Sanaz Karimijafarbigloo and Yuli Wu and Anke Schmeink and Dorit Merhof},
      year={2023},
      eprint={2312.05391},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{DBLP:journals/corr/abs-2010-11929,
  author       = {Alexey Dosovitskiy and
                  Lucas Beyer and
                  Alexander Kolesnikov and
                  Dirk Weissenborn and
                  Xiaohua Zhai and
                  Thomas Unterthiner and
                  Mostafa Dehghani and
                  Matthias Minderer and
                  Georg Heigold and
                  Sylvain Gelly and
                  Jakob Uszkoreit and
                  Neil Houlsby},
  title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition
                  at Scale},
  journal      = {CoRR},
  volume       = {abs/2010.11929},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.11929},
  eprinttype    = {arXiv},
  eprint       = {2010.11929},
  timestamp    = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/RonnebergerFB15,
  author       = {Olaf Ronneberger and
                  Philipp Fischer and
                  Thomas Brox},
  title        = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal      = {CoRR},
  volume       = {abs/1505.04597},
  year         = {2015},
  url          = {http://arxiv.org/abs/1505.04597},
  eprinttype    = {arXiv},
  eprint       = {1505.04597},
  timestamp    = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{DBLP:journals/corr/LinDGHHB16,
  author       = {Tsung{-}Yi Lin and
                  Piotr Doll{\'{a}}r and
                  Ross B. Girshick and
                  Kaiming He and
                  Bharath Hariharan and
                  Serge J. Belongie},
  title        = {Feature Pyramid Networks for Object Detection},
  journal      = {CoRR},
  volume       = {abs/1612.03144},
  year         = {2016},
  url          = {http://arxiv.org/abs/1612.03144},
  eprinttype    = {arXiv},
  eprint       = {1612.03144},
  timestamp    = {Mon, 13 Aug 2018 16:48:50 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/LinDGHHB16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@article{NGUYEN2024360,
title = {Revolutionizing robotized assembly for wire harness: A 3D vision-based method for multiple wire-branch detection},
journal = {Journal of Manufacturing Systems},
volume = {72},
pages = {360-372},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523002509},
author = {Thong Phi Nguyen and Donghyung Kim and Hyun-Kyo Lim and Jonghun Yoon},
keywords = {Automation system, Convolutional neural network, Machine vision, Wire harness assembly},
abstract = {Automating stages for deformable objects in the production line, such as assembling a wire harness into a predefined position, presents a complex task due to the specialized characteristics of these objects. This complexity is further magnified when dealing with a wire harness that has multiple branches. Designing the robot motions and performing the assembly tasks for such target objects not only requires the 3D wire profile of each branch but also entails the identification of each branch. To satisfy this requirement, this study introduces a novel systematic method that processes the point cloud data of the wire harness, captured from a high-quality 3D camera, which provides the constructed wire profiles of branches in the captured frames. The developed method is a combination of a technique to classify the colour of wires and a detecting-matching method to identify the wire terminals, which provides a convenient approach for the proposed tracking method to define the 3D wire profile. The validation of the proposed approach in a real-world robot system not only highlights its incredible usefulness but also demonstrates its immense practicality. This ground-breaking method has the potential to revolutionize factory environments by replacing human labour, leading to substantial cost reductions and increased efficiency.}
}

@article{Wang_2023,
   title={Overview of Computer Vision Techniques in Robotized Wire Harness Assembly: Current State and Future Opportunities},
   volume={120},
   ISSN={2212-8271},
   url={http://dx.doi.org/10.1016/j.procir.2023.09.127},
   DOI={10.1016/j.procir.2023.09.127},
   journal={Procedia CIRP},
   publisher={Elsevier BV},
   author={Wang, Hao and Salunkhe, Omkar and Quadrini, Walter and Lämkull, Dan and Ore, Fredrik and Johansson, Björn and Stahre, Johan},
   year={2023},
   pages={1071–1076} }

@article{DBLP:journals/corr/abs-2103-14030,
  author       = {Ze Liu and
                  Yutong Lin and
                  Yue Cao and
                  Han Hu and
                  Yixuan Wei and
                  Zheng Zhang and
                  Stephen Lin and
                  Baining Guo},
  title        = {Swin Transformer: Hierarchical Vision Transformer using Shifted Windows},
  journal      = {CoRR},
  volume       = {abs/2103.14030},
  year         = {2021},
  url          = {https://arxiv.org/abs/2103.14030},
  eprinttype    = {arXiv},
  eprint       = {2103.14030},
  timestamp    = {Mon, 05 Jun 2023 16:18:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2103-14030.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{10196168,
  author={Žagar, Bare Luka and Caporali, Alessio and Szymko, Amadeusz and Kicki, Piotr and Walas, Krzysztof and Palli, Gianluca and Knoll, Alois C},
  booktitle={2023 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)}, 
  title={Copy and Paste Augmentation for Deformable Wiring Harness Bags Segmentation}, 
  year={2023},
  volume={},
  number={},
  pages={721-726},
  keywords={Wiring;Mechatronics;Semantic segmentation;Wires;Transfer learning;Pipelines;Production facilities;Deformable Objects;Segmentation;Data Augmentation;Industrial Manufacturing},
  doi={10.1109/AIM46323.2023.10196168}}

@INPROCEEDINGS{9665147,
  author={Wnuk, Markus and Hinze, Chistoph and Zürn, Manuel and Pan, Qizhen and Lechler, Armin and Verl, Alexander},
  booktitle={2021 27th International Conference on Mechatronics and Machine Vision in Practice (M2VIP)}, 
  title={Tracking Branched Deformable Linear Objects With Structure Preserved Registration by Branch-wise Probability Modification}, 
  year={2021},
  volume={},
  number={},
  pages={101-108},
  keywords={Point cloud compression;Uncertainty;Runtime;Parameter estimation;Mechatronics;Wires;Object segmentation},
  doi={10.1109/M2VIP49856.2021.9665147}}

@INPROCEEDINGS{10161483,
  author={Zürn, Manuel and Wnuk, Markus and Lechler, Armin and Verl, Alexander},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Topology Matching of Branched Deformable Linear Objects}, 
  year={2023},
  volume={},
  number={},
  pages={7097-7103},
  keywords={Image segmentation;Visualization;Wires;Robot vision systems;Estimation;Cameras;Feature extraction;branched deformable linear object;wire harness localization;graph-based topology matching},
  doi={10.1109/ICRA48891.2023.10161483}}

@InProceedings{10.1007/978-3-031-27933-1_31,
author="Wnuk, Markus
and Z{\"u}rn, Manuel
and Paukner, Matthias
and Ulbrich, Sascha
and Lechler, Armin
and Verl, Alexander",
editor="Kiefl, Niklas
and Wulle, Frederik
and Ackermann, Clemens
and Holder, Daniel",
title="Case Study on Localization for Robotic Wire Harness Installation",
booktitle="Advances in Automotive Production Technology -- Towards Software-Defined Manufacturing and Resilient Supply Chains",
year="2023",
publisher="Springer International Publishing",
address="Cham",
pages="333--343",
abstract="Wire harness installation is one of the most challenging processing steps for automation in automotive production. Wire harnesses have an infinite number of degrees of freedom, such that they change their shape continuously during manipulation. As of today, the human's ability to perceive the wire harness and deal with its shape changes, is unmatched by any technical solution. Therefore, wire harnesses are still installed manually. This paper proposes a concept for wire harness localization and applies it for robotic wire harness installation. The concept uses two stereo cameras, one to perceive the shape of the wire harness and obtain rough position estimates of wire harness components, and a second for accurate 6D pose estimation of the individual components. The concept is evaluated with a case study on localization in a car chassis, where the accuracy and limitations of the concept are investigated by practical experiments.",
isbn="978-3-031-27933-1"
}


@article{10.1093/nsr/nwx106,
    author = {Zhou, Zhi-Hua},
    title = "{A brief introduction to weakly supervised learning}",
    journal = {National Science Review},
    volume = {5},
    number = {1},
    pages = {44-53},
    year = {2017},
    month = {08},
    abstract = "{Supervised learning techniques construct predictive models by learning from a large number of training examples, where each training example has a label indicating its ground-truth output. Though current techniques have achieved great success, it is noteworthy that in many tasks it is difficult to get strong supervision information like fully ground-truth labels due to the high cost of the data-labeling process. Thus, it is desirable for machine-learning techniques to work with weak supervision. This article reviews some research progress of weakly supervised learning, focusing on three typical types of weak supervision: incomplete supervision, where only a subset of training data is given with labels; inexact supervision, where the training data are given with only coarse-grained labels; and inaccurate supervision, where the given labels are not always ground-truth.}",
    issn = {2095-5138},
    doi = {10.1093/nsr/nwx106},
    url = {https://doi.org/10.1093/nsr/nwx106},
    eprint = {https://academic.oup.com/nsr/article-pdf/5/1/44/31567770/nwx106.pdf},
}
@INPROCEEDINGS{9349395,
  author={Zanella, Riccardo and Caporali, Alessio and Tadaka, Kalyan and De Gregorio, Daniele and Palli, Gianluca},
  booktitle={2021 International Conference on Computer, Control and Robotics (ICCCR)}, 
  title={Auto-generated Wires Dataset for Semantic Segmentation with Domain-Independence}, 
  year={2021},
  volume={},
  number={},
  pages={292-298},
  keywords={Training;Image segmentation;Visualization;Wires;Semantics;Robots;Testing;Image Segmentation;Dataset Labeling;Deformable Objects;Chroma-key;Domain Randomization},
  doi={10.1109/ICCCR49711.2021.9349395}}

@article{DBLP:journals/corr/RenHG015,
  author       = {Shaoqing Ren and
                  Kaiming He and
                  Ross B. Girshick and
                  Jian Sun},
  title        = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
                  Networks},
  journal      = {CoRR},
  volume       = {abs/1506.01497},
  year         = {2015},
  url          = {http://arxiv.org/abs/1506.01497},
  eprinttype    = {arXiv},
  eprint       = {1506.01497},
  timestamp    = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/RenHG015.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}}
@article{DBLP:journals/corr/HeGDG17,
  author       = {Kaiming He and
                  Georgia Gkioxari and
                  Piotr Doll{\'{a}}r and
                  Ross B. Girshick},
  title        = {Mask {R-CNN}},
  journal      = {CoRR},
  volume       = {abs/1703.06870},
  year         = {2017},
  url          = {http://arxiv.org/abs/1703.06870},
  eprinttype    = {arXiv},
  eprint       = {1703.06870},
  timestamp    = {Mon, 13 Aug 2018 16:46:36 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HeGDG17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@ARTICLE{Caporali2022,
  author={Caporali, Alessio and Galassi, Kevin and Zanella, Riccardo and Palli, Gianluca},
  journal={IEEE Robotics and Automation Letters}, 
  title={FASTDLO: Fast Deformable Linear Objects Instance Segmentation}, 
  year={2022},
  volume={7},
  number={4},
  pages={9075-9082},
  keywords={Image segmentation;Skeleton;Image color analysis;Wires;Task analysis;Transforms;Training;Deformable Linear Objects;DLO;Instance Segmentation;Industrial Manufacturing;Computer Vision},
  doi={10.1109/LRA.2022.3189791}}


@manual{degregorio2018lets,
      title={Let's take a Walk on Superpixels Graphs: Deformable Linear Objects Segmentation and Model Estimation}, 
      author={Daniele De Gregorio and Gianluca Palli and Luigi Di Stefano},
      year={2018},
      eprint={1810.04461},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2018encoderdecoder,
      title={Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation}, 
      author={Liang-Chieh Chen and Yukun Zhu and George Papandreou and Florian Schroff and Hartwig Adam},
      year={2018},
      eprint={1802.02611},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@ARTICLE{10167643,
  author={Choi, Andrew and Tong, Dezhong and Park, Brian and Terzopoulos, Demetri and Joo, Jungseock and Jawed, Mohammad Khalid},
  journal={IEEE Robotics and Automation Letters}, 
  title={mBEST: Realtime Deformable Linear Object Detection Through Minimal Bending Energy Skeleton Pixel Traversals}, 
  year={2023},
  volume={8},
  number={8},
  pages={4863-4870},
  keywords={Image segmentation;Skeleton;Prediction algorithms;Pipelines;Neural networks;Electronic mail;Bending;Deformable linear objects;DLOs;instance segmentation;computer vision;perception for manipulation},
  doi={10.1109/LRA.2023.3290419}}

@INPROCEEDINGS{10260646,
  author={Zürn, Manuel and Kienzlen, Annika and Klingel, Lars and Lechler, Armin and Verl, Alexander and Ren, Shiyi and Xu, Weiliang},
  booktitle={2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)}, 
  title={Deep Learning-Based Instance Segmentation for Feature Extraction of Branched Deformable Linear Objects for Robotic Manipulation}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  keywords={Deformable models;Connectors;Training;Image segmentation;Automation;Annotations;Wires;Branched Deformable Linear Object;Wire Harness Feature Extraction;Deep Learning;Machine Vision;Robotic Manipulation},
  doi={10.1109/CASE56687.2023.10260646}}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@manual{Kohm2013,
  title = {KOMA-Script -- ein wandelbares LaTeX-2-Paket},
  author = {Markus Kohm and Jens-Uwe Morawski},
  year = {2013},
	url = {http://mirrors.ctan.org/macros/latex/contrib/koma-script/doc/scrguide.pdf},
  langid =  {ngerman}
}

@manual{Cubitt2013,
  title = {The cleveref package},
	author = {Toby Cubitt},
	year = {2013},
	url = {http://mirrors.ctan.org/macros/latex/contrib/cleveref/cleveref.pdf},
  langid = {american}
}

@manual{Fear2005,
  title = {Publication quality tables in LaTeX},
	author = {Simon Fear},
	year = {2005},
	url = {http://mirrors.ctan.org/macros/latex/contrib/booktabs/booktabs.pdf},
  langid = {american}
}

@manual{Cochran2005,
  title = {The Subfig Package},
	author = {Steven Cochran and Vafa Karen-Pahlav},
	year = {2005},
	url = {http://mirrors.ctan.org/macros/latex/contrib/subfig/subfig.pdf},
  langid = {american}
}

@manual{Hoffmann2014,
  title = {The Listings Package},
	author = {Carsten Heinz and  Brooks Moses and  Jobst Hoffmann},
	year = {2014},
	url = {http://mirrors.ctan.org/macros/latex/contrib/listings/listings.pdf},
  langid = {american}
}

@manual{Sommerfeldt2004,
  title = {The rotfloat package},
	author = {Axel Sommerfeldt},
	year = {2004},
	url = {http://mirrors.ctan.org/macros/latex/contrib/rotfloat/rotfloat.pdf},
  langid = {american}
}

@manual{Tantau2013,
  title = {TikZ \& PGF},
	author = {Till Tantau},
	year = {2013},
	url = {http://mirrors.ctan.org/graphics/pgf/base/doc/pgfmanual.pdf},
  langid = {american}
}

@manual{Feuersaenger2014,
  title = {Manual for Package pgfplots},
	author = {Christian Feuersänger},
	year = {2014},
	url = {http://mirrors.ctan.org/graphics/pgf/contrib/pgfplots/doc/pgfplots.pdf},
  langid = {american}
}

@manual{Lehman2013,
  title = {The biblatex Package},
	author = {Philipp Lehman and Philip Kime and Audrey Boruvka and Joseph Wright},
	year = {2013},
	url = {http://mirrors.ctan.org/macros/latex/contrib/biblatex/doc/biblatex.pdf},
  langid = {american}
}

@manual{May2011,
  title = {An Extension of the LaTeX-Theorem Environment},
	author = {Wolfgang May and Andreas Schedler},
	year = {2011},
	url = {http://mirrors.ctan.org/macros/latex/contrib/ntheorem/ntheorem.pdf},
  langid = {american}
}


@manual{ams1999a,
  title = {User’s Guide for the amsmath Package},
	author = {{American Mathematical Society}},
	year = {1999},
	url = {http://mirrors.ctan.org/macros/latex/required/amslatex/math/amsldoc.pdf},
  langid = {american}
}

@manual{ams1999b,
  title = {Sample Paper for the amsmath Package},
	author = {{American Mathematical Society}},
	year = {1999},
	url = {http://mirrors.ctan.org/macros/latex/required/amslatex/math/testmath.pdf},
  langid = {american}
}

@manual{talbot2014,
  title = {User Manual for glossaries.sty v4.09},
	author = {Nicola Talbot},
	year = {2014},
	url = {http://mirrors.ctan.org/macros/latex/contrib/glossaries/glossaries-user.pdf},
  langid = {american}
}
@manual{Kohm2013,
  title = {KOMA-Script -- ein wandelbares LaTeX-2-Paket},
  author = {Markus Kohm and Jens-Uwe Morawski},
  year = {2013},
	url = {http://mirrors.ctan.org/macros/latex/contrib/koma-script/doc/scrguide.pdf},
  langid =  {ngerman}
}

@manual{Cubitt2013,
  title = {The cleveref package},
	author = {Toby Cubitt},
	year = {2013},
	url = {http://mirrors.ctan.org/macros/latex/contrib/cleveref/cleveref.pdf},
  langid = {american}
}

@manual{Fear2005,
  title = {Publication quality tables in LaTeX},
	author = {Simon Fear},
	year = {2005},
	url = {http://mirrors.ctan.org/macros/latex/contrib/booktabs/booktabs.pdf},
  langid = {american}
}

@manual{Cochran2005,
  title = {The Subfig Package},
	author = {Steven Cochran and Vafa Karen-Pahlav},
	year = {2005},
	url = {http://mirrors.ctan.org/macros/latex/contrib/subfig/subfig.pdf},
  langid = {american}
}

@manual{Hoffmann2014,
  title = {The Listings Package},
	author = {Carsten Heinz and  Brooks Moses and  Jobst Hoffmann},
	year = {2014},
	url = {http://mirrors.ctan.org/macros/latex/contrib/listings/listings.pdf},
  langid = {american}
}

@manual{Sommerfeldt2004,
  title = {The rotfloat package},
	author = {Axel Sommerfeldt},
	year = {2004},
	url = {http://mirrors.ctan.org/macros/latex/contrib/rotfloat/rotfloat.pdf},
  langid = {american}
}

@manual{Tantau2013,
  title = {TikZ \& PGF},
	author = {Till Tantau},
	year = {2013},
	url = {http://mirrors.ctan.org/graphics/pgf/base/doc/pgfmanual.pdf},
  langid = {american}
}

@manual{Feuersaenger2014,
  title = {Manual for Package pgfplots},
	author = {Christian Feuersänger},
	year = {2014},
	url = {http://mirrors.ctan.org/graphics/pgf/contrib/pgfplots/doc/pgfplots.pdf},
  langid = {american}
}

@manual{Lehman2013,
  title = {The biblatex Package},
	author = {Philipp Lehman and Philip Kime and Audrey Boruvka and Joseph Wright},
	year = {2013},
	url = {http://mirrors.ctan.org/macros/latex/contrib/biblatex/doc/biblatex.pdf},
  langid = {american}
}

@manual{May2011,
  title = {An Extension of the LaTeX-Theorem Environment},
	author = {Wolfgang May and Andreas Schedler},
	year = {2011},
	url = {http://mirrors.ctan.org/macros/latex/contrib/ntheorem/ntheorem.pdf},
  langid = {american}
}


@manual{ams1999a,
  title = {User’s Guide for the amsmath Package},
	author = {{American Mathematical Society}},
	year = {1999},
	url = {http://mirrors.ctan.org/macros/latex/required/amslatex/math/amsldoc.pdf},
  langid = {american}
}

@manual{ams1999b,
  title = {Sample Paper for the amsmath Package},
	author = {{American Mathematical Society}},
	year = {1999},
	url = {http://mirrors.ctan.org/macros/latex/required/amslatex/math/testmath.pdf},
  langid = {american}
}

@manual{talbot2014,
  title = {User Manual for glossaries.sty v4.09},
	author = {Nicola Talbot},
	year = {2014},
	url = {http://mirrors.ctan.org/macros/latex/contrib/glossaries/glossaries-user.pdf},
  langid = {american}
}